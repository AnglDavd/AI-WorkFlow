name: Smart Caching & Performance

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 1 AM UTC for cache optimization
    - cron: '0 1 * * *'
  workflow_dispatch:

jobs:
  cache-analysis:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Cache Framework Analysis
      id: cache-framework
      uses: actions/cache@v4
      with:
        path: |
          .ai_workflow/cache/
          .ai_workflow/analysis/
        key: framework-analysis-${{ hashFiles('.ai_workflow/**/*.md') }}
        restore-keys: |
          framework-analysis-
    
    - name: Set up environment
      run: |
        chmod +x ./ai-dev
        export AUTO_CONFIRM=true
        export CI_MODE=true
        export CACHE_ENABLED=true
    
    - name: Generate Analysis Cache
      if: steps.cache-framework.outputs.cache-hit != 'true'
      run: |
        echo "ðŸ“Š Generating fresh analysis cache..."
        
        # Create analysis directory
        mkdir -p .ai_workflow/analysis
        
        # Cache framework structure analysis
        find .ai_workflow/workflows -name "*.md" | head -20 | xargs -I {} sh -c 'echo "Analyzing: {}" && wc -l "{}" >> .ai_workflow/analysis/workflow_lines.txt'
        
        # Cache dependency analysis
        ./ai-dev diagnose --focus=dependencies > .ai_workflow/analysis/dependencies.txt
        
        # Cache security patterns
        ./ai-dev audit --dry-run > .ai_workflow/analysis/security_patterns.txt
        
        echo "Cache generated: $(date)" > .ai_workflow/analysis/cache_timestamp.txt
    
    - name: Smart Content Deduplication
      run: |
        echo "ðŸ”„ Analyzing content for deduplication..."
        
        # Find duplicate content blocks
        find .ai_workflow/workflows -name "*.md" -exec grep -l "validation\|security\|error handling" {} \; | head -10 > duplicate_candidates.txt
        
        # Create deduplication report
        echo "## Content Deduplication Analysis" > dedup-report.md
        echo "Generated: $(date)" >> dedup-report.md
        echo "" >> dedup-report.md
        
        # Check for common patterns
        echo "### Common Patterns Found" >> dedup-report.md
        grep -r "## Error Handling" .ai_workflow/workflows/ | wc -l | xargs -I {} echo "Error handling sections: {}" >> dedup-report.md
        grep -r "## Security" .ai_workflow/workflows/ | wc -l | xargs -I {} echo "Security sections: {}" >> dedup-report.md
        grep -r "## Validation" .ai_workflow/workflows/ | wc -l | xargs -I {} echo "Validation sections: {}" >> dedup-report.md
        
        # Suggest consolidation
        echo "" >> dedup-report.md
        echo "### Consolidation Opportunities" >> dedup-report.md
        echo "- Create shared error handling template" >> dedup-report.md
        echo "- Consolidate security validation patterns" >> dedup-report.md
        echo "- Standardize validation procedures" >> dedup-report.md
    
    - name: Performance Optimization Check
      run: |
        echo "âš¡ Checking performance optimization opportunities..."
        
        # Check for performance bottlenecks
        echo "## Performance Analysis" > performance-report.md
        echo "Generated: $(date)" >> performance-report.md
        echo "" >> performance-report.md
        
        # Analyze workflow complexity
        find .ai_workflow/workflows -name "*.md" -exec wc -l {} + | sort -nr | head -5 | while read lines file; do
          echo "High complexity workflow: $file ($lines lines)" >> performance-report.md
        done
        
        # Check for nested loops and complex patterns
        echo "" >> performance-report.md
        echo "### Optimization Recommendations" >> performance-report.md
        echo "- Parallelize independent operations" >> performance-report.md
        echo "- Cache frequent computations" >> performance-report.md
        echo "- Lazy load heavy components" >> performance-report.md
        echo "- Use streaming for large outputs" >> performance-report.md
    
    - name: Upload Analysis Results
      uses: actions/upload-artifact@v4
      with:
        name: smart-analysis-${{ github.run_number }}
        path: |
          dedup-report.md
          performance-report.md
          duplicate_candidates.txt
        retention-days: 30

  intelligent-deployment:
    runs-on: ubuntu-latest
    needs: cache-analysis
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Cache Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/
          /tmp/ai-dev-cache/
        key: deps-${{ runner.os }}-${{ hashFiles('**/package.json', '**/requirements.txt') }}
    
    - name: Conditional Deployment
      run: |
        echo "ðŸš€ Intelligent deployment based on changes..."
        
        # Only run full deployment if critical files changed
        if git diff --name-only HEAD~1 | grep -E "\.(ai_workflow|CLAUDE\.md|manager\.md)"; then
          echo "Critical files changed - full deployment required"
          export DEPLOYMENT_MODE=full
        else
          echo "Non-critical changes - minimal deployment"
          export DEPLOYMENT_MODE=minimal
        fi
        
        # Set deployment mode
        echo "DEPLOYMENT_MODE=$DEPLOYMENT_MODE" >> $GITHUB_ENV
    
    - name: Minimal Deployment
      if: env.DEPLOYMENT_MODE == 'minimal'
      run: |
        echo "âš¡ Running minimal deployment..."
        
        # Run only essential checks
        ./ai-dev status --quiet
        ./ai-dev quality . --quick-check
        
        echo "Minimal deployment completed"
    
    - name: Full Deployment
      if: env.DEPLOYMENT_MODE == 'full'
      run: |
        echo "ðŸ”„ Running full deployment..."
        
        # Run comprehensive checks
        ./ai-dev audit --verbose
        ./ai-dev quality . --comprehensive
        ./ai-dev diagnose --full-report
        
        echo "Full deployment completed"

  resource-optimization:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Optimize Resource Usage
      run: |
        echo "ðŸŽ¯ Optimizing resource usage..."
        
        # Check current resource usage
        df -h > resource-usage.txt
        free -h >> resource-usage.txt
        
        # Optimize temporary files
        find . -name "*.tmp" -o -name "*.temp" -o -name "*.cache" | head -10 | xargs -r rm -f
        
        # Compress large log files
        find .ai_workflow/cache -name "*.log" -size +1M -exec gzip {} \;
        
        # Clean up old artifacts
        find .ai_workflow/cache -name "*.old" -mtime +7 -delete
        
        echo "Resource optimization completed"
    
    - name: Generate Resource Report
      run: |
        echo "ðŸ“Š Generating resource usage report..."
        
        echo "## Resource Usage Report" > resource-report.md
        echo "Generated: $(date)" >> resource-report.md
        echo "" >> resource-report.md
        
        echo "### Current Usage" >> resource-report.md
        echo '```' >> resource-report.md
        cat resource-usage.txt >> resource-report.md
        echo '```' >> resource-report.md
        
        echo "" >> resource-report.md
        echo "### Optimization Actions" >> resource-report.md
        echo "- Cleaned temporary files" >> resource-report.md
        echo "- Compressed large logs" >> resource-report.md
        echo "- Removed old artifacts" >> resource-report.md
        
        # Calculate savings
        echo "" >> resource-report.md
        echo "### Storage Savings" >> resource-report.md
        echo "Estimated space saved: $(du -sh .ai_workflow/cache/ | cut -f1)" >> resource-report.md
    
    - name: Upload Resource Report
      uses: actions/upload-artifact@v4
      with:
        name: resource-report-${{ github.run_number }}
        path: |
          resource-report.md
          resource-usage.txt
        retention-days: 30